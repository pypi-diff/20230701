# Comparing `tmp/qworker-1.9.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip` & `tmp/qworker-1.9.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,37 +1,37 @@
-Zip file size: 320080 bytes, number of entries: 35
-drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 02:58 qworker.libs/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 02:58 qw/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 02:58 qworker-1.9.2.dist-info/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 02:58 qw/executor/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 02:58 qw/utils/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 02:58 qw/queues/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 02:58 qw/wrappers/
--rw-r--r--  2.0 unx     3025 b- defN 23-Jul-01 02:58 qw/conf.py
--rw-r--r--  2.0 unx      622 b- defN 23-Jul-01 02:58 qw/version.py
--rw-r--r--  2.0 unx      137 b- defN 23-Jul-01 02:58 qw/__init__.py
--rw-r--r--  2.0 unx     4129 b- defN 23-Jul-01 02:58 qw/protocols.py
--rw-r--r--  2.0 unx    18628 b- defN 23-Jul-01 02:58 qw/client.py
--rw-r--r--  2.0 unx     2160 b- defN 23-Jul-01 02:58 qw/discovery.py
--rw-r--r--  2.0 unx     8058 b- defN 23-Jul-01 02:58 qw/process.py
--rw-r--r--  2.0 unx    22119 b- defN 23-Jul-01 02:58 qw/server.py
--rw-r--r--  2.0 unx      380 b- defN 23-Jul-01 02:58 qw/decorators.py
--rwxr-xr-x  2.0 unx   568544 b- defN 23-Jul-01 02:58 qw/exceptions.cpython-39-x86_64-linux-gnu.so
--rw-r--r--  2.0 unx     2472 b- defN 23-Jul-01 02:58 qw/__main__.py
--rw-r--r--  2.0 unx     4265 b- defN 23-Jul-01 02:58 qw/executor/__init__.py
--rw-r--r--  2.0 unx       46 b- defN 23-Jul-01 02:58 qw/utils/__init__.py
--rw-r--r--  2.0 unx      512 b- defN 23-Jul-01 02:58 qw/utils/functions.py
--rwxr-xr-x  2.0 unx   434800 b- defN 23-Jul-01 02:58 qw/utils/json.cpython-39-x86_64-linux-gnu.so
--rw-r--r--  2.0 unx      597 b- defN 23-Jul-01 02:58 qw/utils/versions.py
--rw-r--r--  2.0 unx       62 b- defN 23-Jul-01 02:58 qw/queues/__init__.py
--rw-r--r--  2.0 unx     6008 b- defN 23-Jul-01 02:58 qw/queues/manager.py
--rw-r--r--  2.0 unx     1246 b- defN 23-Jul-01 02:58 qw/wrappers/func.py
--rw-r--r--  2.0 unx     4658 b- defN 23-Jul-01 02:58 qw/wrappers/di_task.py
--rw-r--r--  2.0 unx      320 b- defN 23-Jul-01 02:58 qw/wrappers/__init__.py
--rw-r--r--  2.0 unx     1483 b- defN 23-Jul-01 02:58 qw/wrappers/base.py
--rw-r--r--  2.0 unx     3170 b- defN 23-Jul-01 02:58 qworker-1.9.2.dist-info/METADATA
--rw-r--r--  2.0 unx       40 b- defN 23-Jul-01 02:58 qworker-1.9.2.dist-info/entry_points.txt
--rw-r--r--  2.0 unx     1070 b- defN 23-Jul-01 02:58 qworker-1.9.2.dist-info/LICENSE
--rw-r--r--  2.0 unx        3 b- defN 23-Jul-01 02:58 qworker-1.9.2.dist-info/top_level.txt
--rw-r--r--  2.0 unx      217 b- defN 23-Jul-01 02:58 qworker-1.9.2.dist-info/WHEEL
--rw-rw-r--  2.0 unx     2189 b- defN 23-Jul-01 02:58 qworker-1.9.2.dist-info/RECORD
-35 files, 1090960 bytes uncompressed, 315974 bytes compressed:  71.0%
+Zip file size: 320176 bytes, number of entries: 35
+drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 17:46 qworker.libs/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 17:46 qw/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 17:46 qworker-1.9.3.dist-info/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 17:46 qw/executor/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 17:46 qw/utils/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 17:46 qw/queues/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Jul-01 17:46 qw/wrappers/
+-rw-r--r--  2.0 unx     3025 b- defN 23-Jul-01 17:46 qw/conf.py
+-rw-r--r--  2.0 unx      622 b- defN 23-Jul-01 17:46 qw/version.py
+-rw-r--r--  2.0 unx      137 b- defN 23-Jul-01 17:46 qw/__init__.py
+-rw-r--r--  2.0 unx     4129 b- defN 23-Jul-01 17:46 qw/protocols.py
+-rw-r--r--  2.0 unx    18770 b- defN 23-Jul-01 17:46 qw/client.py
+-rw-r--r--  2.0 unx     2160 b- defN 23-Jul-01 17:46 qw/discovery.py
+-rw-r--r--  2.0 unx     8058 b- defN 23-Jul-01 17:46 qw/process.py
+-rw-r--r--  2.0 unx    22230 b- defN 23-Jul-01 17:46 qw/server.py
+-rw-r--r--  2.0 unx      380 b- defN 23-Jul-01 17:46 qw/decorators.py
+-rwxr-xr-x  2.0 unx   568544 b- defN 23-Jul-01 17:46 qw/exceptions.cpython-39-x86_64-linux-gnu.so
+-rw-r--r--  2.0 unx     2472 b- defN 23-Jul-01 17:46 qw/__main__.py
+-rw-r--r--  2.0 unx     4265 b- defN 23-Jul-01 17:46 qw/executor/__init__.py
+-rw-r--r--  2.0 unx       46 b- defN 23-Jul-01 17:46 qw/utils/__init__.py
+-rw-r--r--  2.0 unx      512 b- defN 23-Jul-01 17:46 qw/utils/functions.py
+-rwxr-xr-x  2.0 unx   434800 b- defN 23-Jul-01 17:46 qw/utils/json.cpython-39-x86_64-linux-gnu.so
+-rw-r--r--  2.0 unx      597 b- defN 23-Jul-01 17:46 qw/utils/versions.py
+-rw-r--r--  2.0 unx       62 b- defN 23-Jul-01 17:46 qw/queues/__init__.py
+-rw-r--r--  2.0 unx     6118 b- defN 23-Jul-01 17:46 qw/queues/manager.py
+-rw-r--r--  2.0 unx     1246 b- defN 23-Jul-01 17:46 qw/wrappers/func.py
+-rw-r--r--  2.0 unx     4658 b- defN 23-Jul-01 17:46 qw/wrappers/di_task.py
+-rw-r--r--  2.0 unx      320 b- defN 23-Jul-01 17:46 qw/wrappers/__init__.py
+-rw-r--r--  2.0 unx     1483 b- defN 23-Jul-01 17:46 qw/wrappers/base.py
+-rw-r--r--  2.0 unx     3170 b- defN 23-Jul-01 17:46 qworker-1.9.3.dist-info/METADATA
+-rw-r--r--  2.0 unx       40 b- defN 23-Jul-01 17:46 qworker-1.9.3.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx     1070 b- defN 23-Jul-01 17:46 qworker-1.9.3.dist-info/LICENSE
+-rw-r--r--  2.0 unx        3 b- defN 23-Jul-01 17:46 qworker-1.9.3.dist-info/top_level.txt
+-rw-r--r--  2.0 unx      217 b- defN 23-Jul-01 17:46 qworker-1.9.3.dist-info/WHEEL
+-rw-rw-r--  2.0 unx     2189 b- defN 23-Jul-01 17:46 qworker-1.9.3.dist-info/RECORD
+35 files, 1091323 bytes uncompressed, 316070 bytes compressed:  71.0%
```

## zipnote {}

```diff
@@ -1,14 +1,14 @@
 Filename: qworker.libs/
 Comment: 
 
 Filename: qw/
 Comment: 
 
-Filename: qworker-1.9.2.dist-info/
+Filename: qworker-1.9.3.dist-info/
 Comment: 
 
 Filename: qw/executor/
 Comment: 
 
 Filename: qw/utils/
 Comment: 
@@ -81,26 +81,26 @@
 
 Filename: qw/wrappers/__init__.py
 Comment: 
 
 Filename: qw/wrappers/base.py
 Comment: 
 
-Filename: qworker-1.9.2.dist-info/METADATA
+Filename: qworker-1.9.3.dist-info/METADATA
 Comment: 
 
-Filename: qworker-1.9.2.dist-info/entry_points.txt
+Filename: qworker-1.9.3.dist-info/entry_points.txt
 Comment: 
 
-Filename: qworker-1.9.2.dist-info/LICENSE
+Filename: qworker-1.9.3.dist-info/LICENSE
 Comment: 
 
-Filename: qworker-1.9.2.dist-info/top_level.txt
+Filename: qworker-1.9.3.dist-info/top_level.txt
 Comment: 
 
-Filename: qworker-1.9.2.dist-info/WHEEL
+Filename: qworker-1.9.3.dist-info/WHEEL
 Comment: 
 
-Filename: qworker-1.9.2.dist-info/RECORD
+Filename: qworker-1.9.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## qw/version.py

```diff
@@ -2,15 +2,15 @@
    QueueWorker is a asyncio-based Worker for distributed functions.
 """
 
 __title__ = 'qworker'
 __description__ = ('QueueWorker is asynchronous Task Queue implementation '
                    'built on top of Asyncio.'
                    'Can you spawn distributed workers to run functions inside workers.')
-__version__ = '1.9.2'
+__version__ = '1.9.3'
 __author__ = 'Jesus Lara'
 __author_email__ = 'jesuslarag@gmail.com'
 __license__ = 'MIT'
 
 def get_version() -> tuple:  # pragma: no cover
     """ Get Queue Worker version as tuple.
     """
```

## qw/client.py

```diff
@@ -25,14 +25,15 @@
     DiscardedTask
 )
 from .conf import (
     WORKER_DEFAULT_HOST,
     WORKER_DEFAULT_PORT,
     WORKER_REDIS,
     REDIS_WORKER_STREAM,
+    REDIS_WORKER_GROUP,
     USE_DISCOVERY,
     WORKER_SECRET_KEY,
     expected_message
 )
 from .process import QW_WORKER_LIST
 from .wrappers import FuncWrapper, TaskWrapper
 
@@ -496,15 +497,15 @@
             None.
 
         Raises:
             ConfigError: bad instructions to Worker Client.
             ConnectionError: unable to connect to Worker.
             Exception: Any Unhandled error.
         """
-        self.logger.debug(
+        self.logger.info(
             f'Sending function {fn!s} to Pub/Sub Channel {REDIS_WORKER_STREAM}'
         )
         host = socket.gethostbyname(socket.gethostname())
         # serializing
         func = self.get_wrapped_function(
             fn,
             host,
@@ -517,37 +518,38 @@
             uid = func.id
         else:
             uid = uuid.uuid1(
                 node=random.getrandbits(48) | 0x010000000000
             )
         serialized_task = cloudpickle.dumps(func)
         encoded_task = base64.b64encode(serialized_task).decode('utf-8')
-        # conn = aioredis.from_url(
-        #     WORKER_REDIS,
-        #     decode_responses=True,
-        #     encoding='utf-8'
-        # )
         message = {
             "uid": str(uid),
             "task": encoded_task
         }
         # check if published
         # Add the data to the stream
         try:
             async with aioredis.from_url(
                     WORKER_REDIS,
                     decode_responses=True,
                     encoding='utf-8'
             ) as conn:
-                result = await conn.xadd(REDIS_WORKER_STREAM, message)
+                self.logger.debug(
+                    f"Redis Server:  {conn}"
+                )
+                result = await conn.xadd(REDIS_WORKER_STREAM, message, nomkstream=False)
                 serialized_result = {
                     "status": "Queued",
                     "task": f"{func!r}",
                     "message": result
                 }
+                self.logger.info(
+                    f"Task {fn!r} was published to {REDIS_WORKER_GROUP}-{REDIS_WORKER_STREAM}"
+                )
                 return serialized_result
         finally:
             try:
                 await conn.close()
             except Exception as exc:
                 logging.warning(
                     f"Failed to disconnect Redis: {exc}"
```

## qw/server.py

```diff
@@ -121,14 +121,17 @@
 
     async def start_subscription(self):
         """Starts stream consumer group based on Redis."""
         try:
             await self.ensure_group_exists()
             info = await self.redis.xinfo_groups(REDIS_WORKER_STREAM)
             self.logger.debug(f'Groups Info: {info}')
+            self.logger.debug(
+                f"Redis Server: {self.redis}"
+            )
             while self._running:
                 try:
                     message_groups = await self.redis.xreadgroup(
                         REDIS_WORKER_GROUP,
                         self._name,
                         streams={REDIS_WORKER_STREAM: '>'},
                         block=100,
@@ -139,21 +142,21 @@
                             try:
                                 encoded_task = fn['task']
                                 task_id = fn['uid']
                                 # Process the task
                                 serialized_task = base64.b64decode(encoded_task)
                                 task = cloudpickle.loads(serialized_task)
                                 self.logger.info(
-                                    f'TASK RECEIVED: {task} with id {task_id} at {int(time.time())}'
+                                    f':: TASK RECEIVED from Publish: {task} with id {task_id} at {int(time.time())}'
                                 )
                                 try:
                                     executor = TaskExecutor(task)
                                     await executor.run()
                                     self.logger.info(
-                                        f":: TASK {task}.{task_id} Executed at {int(time.time())}"
+                                        f":: TASK {task}.{task_id} was executed at {int(time.time())}"
                                     )
                                 except Exception as e:
                                     self.logger.error(
                                         f"Task {task}:{task_id} failed with error {e}"
                                     )
                                 # If processing raises an exception, the next line won't be executed
                                 await self.redis.xack(
```

## qw/queues/manager.py

```diff
@@ -1,16 +1,18 @@
 import asyncio
 import time
 from typing import Union
 from collections.abc import Awaitable, Callable
 import importlib
 from navconfig.logging import logging
 from flowtask.exceptions import (
+    NotFound,
     DataNotFound,
-    FileNotFound
+    FileNotFound,
+    FileError
 )
 from qw.exceptions import QWException
 from ..conf import (
     WORKER_QUEUE_SIZE,
     WORKER_RETRY_INTERVAL,
     WORKER_RETRY_COUNT,
     WORKER_QUEUE_CALLBACK
@@ -138,17 +140,18 @@
             )
             ### Process Task:
             try:
                 executor = TaskExecutor(task)
                 result = await executor.run()
                 if type(result) == asyncio.TimeoutError:
                     raise
-                elif type(result) in (DataNotFound, FileNotFound):
+                elif type(result) in (NotFound, DataNotFound, FileNotFound, FileError):
                     raise
                 elif isinstance(result, BaseException):
+                    ## TODO: checking retry info from Task.
                     if task.retries < WORKER_RETRY_COUNT - 1:
                         task.add_retries()
                         self.logger.warning(
                             f"Task {task} failed. Retrying. Retry count: {task.retries}"
                         )
                         # Wait some seconds before retrying.
                         await asyncio.sleep(WORKER_RETRY_INTERVAL)
```

## Comparing `qworker-1.9.2.dist-info/METADATA` & `qworker-1.9.3.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: qworker
-Version: 1.9.2
+Version: 1.9.3
 Summary: QueueWorker is asynchronous Task Queue implementation built on top of Asyncio.Can you spawn distributed workers to run functions inside workers.
 Home-page: https://github.com/phenobarbital/qworker
 Author: Jesus Lara
 Author-email: jesuslara@phenobarbital.info
 License: MIT
 Project-URL: Source, https://github.com/phenobarbital/qworker
 Project-URL: Funding, https://paypal.me/phenobarbital
```

## Comparing `qworker-1.9.2.dist-info/LICENSE` & `qworker-1.9.3.dist-info/LICENSE`

 * *Files identical despite different names*

