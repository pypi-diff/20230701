# Comparing `tmp/cmrsim-0.26-py3-none-any.whl.zip` & `tmp/cmrsim-0.27-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,54 +1,54 @@
-Zip file size: 119241 bytes, number of entries: 52
--rw-r--r--  2.0 unx      317 b- defN 23-Apr-21 09:27 cmrsim/__init__.py
--rw-r--r--  2.0 unx      354 b- defN 23-Apr-13 14:50 cmrsim/analytic/__init__.py
--rw-r--r--  2.0 unx     5002 b- defN 23-Apr-13 14:50 cmrsim/analytic/_composite_signal.py
--rw-r--r--  2.0 unx    14188 b- defN 23-Apr-13 14:50 cmrsim/analytic/simulation.py
--rw-r--r--  2.0 unx      790 b- defN 23-Apr-18 15:24 cmrsim/analytic/contrast/__init__.py
--rw-r--r--  2.0 unx    15609 b- defN 23-Apr-13 14:50 cmrsim/analytic/contrast/base.py
--rw-r--r--  2.0 unx    12878 b- defN 23-Apr-13 14:50 cmrsim/analytic/contrast/coil_sensitivities.py
--rw-r--r--  2.0 unx     4067 b- defN 23-Apr-13 14:50 cmrsim/analytic/contrast/diffusion_weighting.py
--rw-r--r--  2.0 unx     4797 b- defN 23-Apr-18 15:24 cmrsim/analytic/contrast/offresonance.py
--rw-r--r--  2.0 unx     4409 b- defN 23-Apr-13 14:50 cmrsim/analytic/contrast/phase_tracking.py
--rw-r--r--  2.0 unx    13174 b- defN 23-Apr-13 14:50 cmrsim/analytic/contrast/sequences.py
--rw-r--r--  2.0 unx     4764 b- defN 23-Apr-13 14:50 cmrsim/analytic/contrast/t2_star.py
--rw-r--r--  2.0 unx      707 b- defN 23-Apr-13 14:50 cmrsim/analytic/encoding/__init__.py
--rw-r--r--  2.0 unx     2010 b- defN 23-Apr-13 14:50 cmrsim/analytic/encoding/_from_sequence.py
--rw-r--r--  2.0 unx    15979 b- defN 23-Apr-13 14:50 cmrsim/analytic/encoding/base.py
--rw-r--r--  2.0 unx     9365 b- defN 23-Apr-13 14:50 cmrsim/analytic/encoding/cartesian.py
--rw-r--r--  2.0 unx      493 b- defN 23-Apr-13 14:50 cmrsim/bloch/__init__.py
--rw-r--r--  2.0 unx     5423 b- defN 23-Apr-13 14:50 cmrsim/bloch/_base.py
--rw-r--r--  2.0 unx    27333 b- defN 23-Apr-18 15:24 cmrsim/bloch/_generic.py
--rw-r--r--  2.0 unx     3456 b- defN 23-Apr-13 14:50 cmrsim/bloch/_ideal.py
--rw-r--r--  2.0 unx     6674 b- defN 23-Apr-13 14:50 cmrsim/bloch/_multi_coil.py
--rw-r--r--  2.0 unx     7960 b- defN 23-Apr-21 09:01 cmrsim/bloch/submodules.py
--rw-r--r--  2.0 unx      702 b- defN 23-Apr-13 14:50 cmrsim/datasets/__init__.py
--rw-r--r--  2.0 unx     3804 b- defN 23-Apr-13 14:50 cmrsim/datasets/_analytic.py
--rw-r--r--  2.0 unx     2842 b- defN 23-Apr-13 14:50 cmrsim/datasets/_base.py
--rw-r--r--  2.0 unx     1655 b- defN 23-Apr-13 14:50 cmrsim/datasets/_bloch.py
--rw-r--r--  2.0 unx    41423 b- defN 23-Apr-19 12:18 cmrsim/datasets/_cardiac_mesh.py
--rw-r--r--  2.0 unx    23224 b- defN 23-Apr-19 12:18 cmrsim/datasets/_flow.py
--rw-r--r--  2.0 unx    14057 b- defN 23-Apr-13 14:50 cmrsim/datasets/_regular_grid.py
--rw-r--r--  2.0 unx      140 b- defN 23-Apr-13 14:50 cmrsim/reconstruction/__init__.py
--rw-r--r--  2.0 unx     1820 b- defN 23-Apr-13 14:50 cmrsim/reconstruction/base.py
--rw-r--r--  2.0 unx     6823 b- defN 23-Apr-13 14:50 cmrsim/reconstruction/cartesian.py
--rw-r--r--  2.0 unx      189 b- defN 23-Apr-13 14:50 cmrsim/simulation_templates/__init__.py
--rw-r--r--  2.0 unx     9173 b- defN 23-Apr-13 14:50 cmrsim/simulation_templates/experimental_optimization.py
--rw-r--r--  2.0 unx    20333 b- defN 23-Apr-21 09:01 cmrsim/simulation_templates/flow.py
--rw-r--r--  2.0 unx     1437 b- defN 23-Apr-18 15:24 cmrsim/trajectory/__init__.py
--rw-r--r--  2.0 unx     3296 b- defN 23-Apr-13 14:50 cmrsim/trajectory/_base.py
--rw-r--r--  2.0 unx     5577 b- defN 23-Apr-19 13:20 cmrsim/trajectory/_breathing.py
--rw-r--r--  2.0 unx     8492 b- defN 23-Apr-13 14:50 cmrsim/trajectory/_diffusion.py
--rw-r--r--  2.0 unx    26071 b- defN 23-Apr-21 09:01 cmrsim/trajectory/_flow.py
--rw-r--r--  2.0 unx     8394 b- defN 23-Apr-18 15:24 cmrsim/trajectory/_proper_ortho_decomp.py
--rw-r--r--  2.0 unx     7443 b- defN 23-Apr-19 12:18 cmrsim/trajectory/_taylor.py
--rw-r--r--  2.0 unx      376 b- defN 23-Apr-13 14:50 cmrsim/utils/__init__.py
--rw-r--r--  2.0 unx     4170 b- defN 23-Apr-13 14:50 cmrsim/utils/coordinates.py
--rw-r--r--  2.0 unx     6671 b- defN 23-Apr-13 14:50 cmrsim/utils/display.py
--rw-r--r--  2.0 unx     1246 b- defN 23-Apr-13 14:50 cmrsim/utils/particle_properties.py
--rw-r--r--  2.0 unx     7023 b- defN 23-Apr-13 14:50 cmrsim/utils/snr.py
--rw-rw-rw-  2.0 unx    35060 b- defN 23-Apr-21 09:27 cmrsim-0.26.dist-info/LICENSE
--rw-r--r--  2.0 unx     3473 b- defN 23-Apr-21 09:27 cmrsim-0.26.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-21 09:27 cmrsim-0.26.dist-info/WHEEL
--rw-r--r--  2.0 unx        7 b- defN 23-Apr-21 09:27 cmrsim-0.26.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     4531 b- defN 23-Apr-21 09:27 cmrsim-0.26.dist-info/RECORD
-52 files, 409293 bytes uncompressed, 112021 bytes compressed:  72.6%
+Zip file size: 119785 bytes, number of entries: 52
+-rw-r--r--  2.0 unx      317 b- defN 23-Jul-01 10:11 cmrsim/__init__.py
+-rw-r--r--  2.0 unx      354 b- defN 23-Jun-30 14:07 cmrsim/analytic/__init__.py
+-rw-r--r--  2.0 unx     5193 b- defN 23-Jun-30 14:07 cmrsim/analytic/_composite_signal.py
+-rw-r--r--  2.0 unx    14908 b- defN 23-Jul-01 09:12 cmrsim/analytic/simulation.py
+-rw-r--r--  2.0 unx      790 b- defN 23-Jun-30 14:07 cmrsim/analytic/contrast/__init__.py
+-rw-r--r--  2.0 unx    15609 b- defN 23-Jun-30 14:07 cmrsim/analytic/contrast/base.py
+-rw-r--r--  2.0 unx    12878 b- defN 23-Jun-30 14:07 cmrsim/analytic/contrast/coil_sensitivities.py
+-rw-r--r--  2.0 unx     4067 b- defN 23-Jun-30 14:07 cmrsim/analytic/contrast/diffusion_weighting.py
+-rw-r--r--  2.0 unx     4790 b- defN 23-Jul-01 09:12 cmrsim/analytic/contrast/offresonance.py
+-rw-r--r--  2.0 unx     4409 b- defN 23-Jun-30 14:07 cmrsim/analytic/contrast/phase_tracking.py
+-rw-r--r--  2.0 unx    13174 b- defN 23-Jun-30 14:07 cmrsim/analytic/contrast/sequences.py
+-rw-r--r--  2.0 unx     4764 b- defN 23-Jun-30 14:07 cmrsim/analytic/contrast/t2_star.py
+-rw-r--r--  2.0 unx      707 b- defN 23-Jun-30 14:07 cmrsim/analytic/encoding/__init__.py
+-rw-r--r--  2.0 unx     2247 b- defN 23-Jun-30 14:07 cmrsim/analytic/encoding/_from_sequence.py
+-rw-r--r--  2.0 unx    16191 b- defN 23-Jun-30 14:07 cmrsim/analytic/encoding/base.py
+-rw-r--r--  2.0 unx     9396 b- defN 23-Jun-30 14:07 cmrsim/analytic/encoding/cartesian.py
+-rw-r--r--  2.0 unx      493 b- defN 23-Jun-30 14:07 cmrsim/bloch/__init__.py
+-rw-r--r--  2.0 unx     5423 b- defN 23-Jun-30 14:07 cmrsim/bloch/_base.py
+-rw-r--r--  2.0 unx    27333 b- defN 23-Jun-30 14:07 cmrsim/bloch/_generic.py
+-rw-r--r--  2.0 unx     3456 b- defN 23-Jun-30 14:07 cmrsim/bloch/_ideal.py
+-rw-r--r--  2.0 unx     6674 b- defN 23-Jun-30 14:07 cmrsim/bloch/_multi_coil.py
+-rw-r--r--  2.0 unx     7960 b- defN 23-Jun-30 14:07 cmrsim/bloch/submodules.py
+-rw-r--r--  2.0 unx      702 b- defN 23-Jun-30 14:07 cmrsim/datasets/__init__.py
+-rw-r--r--  2.0 unx     3804 b- defN 23-Jun-30 14:07 cmrsim/datasets/_analytic.py
+-rw-r--r--  2.0 unx     2842 b- defN 23-Jun-30 14:07 cmrsim/datasets/_base.py
+-rw-r--r--  2.0 unx     1655 b- defN 23-Jun-30 14:07 cmrsim/datasets/_bloch.py
+-rw-r--r--  2.0 unx    41560 b- defN 23-Jul-01 09:12 cmrsim/datasets/_cardiac_mesh.py
+-rw-r--r--  2.0 unx    23224 b- defN 23-Jul-01 08:59 cmrsim/datasets/_flow.py
+-rw-r--r--  2.0 unx    14057 b- defN 23-Jun-30 14:07 cmrsim/datasets/_regular_grid.py
+-rw-r--r--  2.0 unx      140 b- defN 23-Jun-30 14:07 cmrsim/reconstruction/__init__.py
+-rw-r--r--  2.0 unx     1820 b- defN 23-Jun-30 14:07 cmrsim/reconstruction/base.py
+-rw-r--r--  2.0 unx     6823 b- defN 23-Jun-30 14:07 cmrsim/reconstruction/cartesian.py
+-rw-r--r--  2.0 unx      189 b- defN 23-Jun-30 14:07 cmrsim/simulation_templates/__init__.py
+-rw-r--r--  2.0 unx     9173 b- defN 23-Jun-30 14:07 cmrsim/simulation_templates/experimental_optimization.py
+-rw-r--r--  2.0 unx    20333 b- defN 23-Jun-30 14:07 cmrsim/simulation_templates/flow.py
+-rw-r--r--  2.0 unx     1437 b- defN 23-Jun-30 14:07 cmrsim/trajectory/__init__.py
+-rw-r--r--  2.0 unx     3299 b- defN 23-Jun-30 14:07 cmrsim/trajectory/_base.py
+-rw-r--r--  2.0 unx     5577 b- defN 23-Jun-30 14:07 cmrsim/trajectory/_breathing.py
+-rw-r--r--  2.0 unx     8492 b- defN 23-Jun-30 14:07 cmrsim/trajectory/_diffusion.py
+-rw-r--r--  2.0 unx    26071 b- defN 23-Jul-01 08:59 cmrsim/trajectory/_flow.py
+-rw-r--r--  2.0 unx     9158 b- defN 23-Jun-30 14:07 cmrsim/trajectory/_proper_ortho_decomp.py
+-rw-r--r--  2.0 unx     7554 b- defN 23-Jun-30 14:07 cmrsim/trajectory/_taylor.py
+-rw-r--r--  2.0 unx      376 b- defN 23-Jun-30 14:07 cmrsim/utils/__init__.py
+-rw-r--r--  2.0 unx     4170 b- defN 23-Jun-30 14:07 cmrsim/utils/coordinates.py
+-rw-r--r--  2.0 unx     6671 b- defN 23-Jun-30 14:07 cmrsim/utils/display.py
+-rw-r--r--  2.0 unx     1246 b- defN 23-Jun-30 14:07 cmrsim/utils/particle_properties.py
+-rw-r--r--  2.0 unx     7023 b- defN 23-Jun-30 14:07 cmrsim/utils/snr.py
+-rw-rw-rw-  2.0 unx    35060 b- defN 23-Jul-01 10:11 cmrsim-0.27.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3473 b- defN 23-Jul-01 10:11 cmrsim-0.27.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-01 10:11 cmrsim-0.27.dist-info/WHEEL
+-rw-r--r--  2.0 unx        7 b- defN 23-Jul-01 10:11 cmrsim-0.27.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4531 b- defN 23-Jul-01 10:11 cmrsim-0.27.dist-info/RECORD
+52 files, 411692 bytes uncompressed, 112565 bytes compressed:  72.7%
```

## zipnote {}

```diff
@@ -135,23 +135,23 @@
 
 Filename: cmrsim/utils/particle_properties.py
 Comment: 
 
 Filename: cmrsim/utils/snr.py
 Comment: 
 
-Filename: cmrsim-0.26.dist-info/LICENSE
+Filename: cmrsim-0.27.dist-info/LICENSE
 Comment: 
 
-Filename: cmrsim-0.26.dist-info/METADATA
+Filename: cmrsim-0.27.dist-info/METADATA
 Comment: 
 
-Filename: cmrsim-0.26.dist-info/WHEEL
+Filename: cmrsim-0.27.dist-info/WHEEL
 Comment: 
 
-Filename: cmrsim-0.26.dist-info/top_level.txt
+Filename: cmrsim-0.27.dist-info/top_level.txt
 Comment: 
 
-Filename: cmrsim-0.26.dist-info/RECORD
+Filename: cmrsim-0.27.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cmrsim/__init__.py

```diff
@@ -1,8 +1,8 @@
-__version__ = '0.26'
+__version__ = '0.27'
 __all__ = ["trajectory", "analytic", "bloch",
            "datasets", "reconstruction", "simulation_templates", "utils"]
 
 import cmrsim.analytic
 import cmrsim.utils
 import cmrsim.bloch
 import cmrsim.datasets
```

## cmrsim/analytic/_composite_signal.py

```diff
@@ -59,14 +59,19 @@
         """
         kwargs.update({'segment_index': segment_index})
         for sub_mod_name in self._sub_module_order:
             sub_mod = self.__dict__[sub_mod_name]
             signal_tensor = sub_mod(signal_tensor, **kwargs)
         return signal_tensor
 
+    def __str__(self):
+        string = "CompositeSignalModel: \n\t"
+        string += "\n\t".join([f"{self.__dict__[sbm]}: {sbm}" for sbm in self._sub_module_order])
+        return string
+
     def update(self):
         """ Calls update function of all sub-modules and records the overall expansion factor """
         self._expansion_factors = ()
         self._expansion_names = ()
         for module_name in self._sub_module_order:
             module = self.__dict__[module_name]
             module.update()
@@ -100,7 +105,8 @@
         self.update()
         input_shape = tf.shape(simulation_result)
         unstacked_repetitions_shape = tuple(
                 (f for (f, apply) in zip(self._expansion_factors[::-1], self._apply_expansion[::-1])
                  if (f > 1 and apply)))
         resulting_shape = tf.concat((unstacked_repetitions_shape, input_shape[1:]), 0)
         return tf.reshape(simulation_result, resulting_shape)
+
```

## cmrsim/analytic/simulation.py

```diff
@@ -144,39 +144,48 @@
         s_of_k_temp *= (0. + 0.j)
         # Loop over material points in dataset
         for batch_idx, batch_dict in dataset.enumerate():
             if trajectory_module is not None:
                 batch_dict = self._map_trajectories(batch_idx, batch_dict, trajectory_module,
                                                     trajectory_signatures, additional_kwargs)
                 # print([f"{k}: {v.shape}" for k, v in batch_dict.items()])
-            s_of_k_temp += self._segment_loop(batch_dict)
+            s_of_k_temp += self._segment_loop(**batch_dict)
             self.progress_bar.update(add_voxels=tf.shape(batch_dict['M0'])[0])
             self.progress_bar.print()
 
         self.progress_bar.print_final()
         return s_of_k_temp
 
     @tf.function(jit_compile=False, reduce_retracing=True)
-    def _segment_loop(self, batch_dict: dict):
+    def _segment_loop(self, **batch_dict):
         """ Fourier transforms the handed batch of object points / isochromates,
 
         :param batch_dict: dictionary of type {'property_name': tf.Tensor(...)}
                            e.g. {'M0': tf.Tensor{}}
         :return: tf.Tensor of shape (1, #repetitions, #k-space-samples)
         """
         # Allocate k-space-Tensor
         n_segments = self.encoding_module.k_space_segments.read_value()
         s_of_k_segments = tf.TensorArray(dtype=tf.complex64, size=n_segments, dynamic_size=False)
         self.progress_bar.reset_segments()
- 
-        # Loop over k-space segments, defined by k-space trajectory in self.encoding_module
+
         m_transverse = self.forward_model(batch_dict["M0"], segment_index=0, **batch_dict)
+
+        samples_per_segment = tf.cast(self.encoding_module.number_of_samples /
+                                      self.encoding_module.k_space_segments, tf.int32)
+        max_mtrans_index = tf.math.reduce_min(tf.stack([tf.shape(m_transverse)[-1], n_segments]))
+        max_rvectrans_index = tf.math.reduce_min(tf.stack([tf.shape(batch_dict['r_vectors'])[-2], n_segments]))
+
+        # Loop over k-space segments, defined by k-space trajectory in self.encoding_module
         for segment_index in tf.range(n_segments):
-            k_space_segment = self.encoding_module(m_transverse, batch_dict['r_vectors'],
-                                                   segment_index=segment_index)
+            mseg_idx = tf.reduce_min(tf.stack([segment_index + 1, max_mtrans_index]))
+            rseg_idx = tf.reduce_min(tf.stack([segment_index + 1, max_rvectrans_index]))
+            m_segment = m_transverse[..., samples_per_segment * (mseg_idx - 1): samples_per_segment * mseg_idx]
+            r_segment = batch_dict['r_vectors'][..., samples_per_segment * (rseg_idx - 1):samples_per_segment*rseg_idx, :]
+            k_space_segment = self.encoding_module(m_segment, r_segment, segment_index=segment_index)
             k_space_segment = tf.transpose(k_space_segment, [1, 0])
             s_of_k_segments = s_of_k_segments.write(segment_index, k_space_segment)
 
             self.progress_bar.update(add_segment=1)
             if tf.math.floormod(segment_index, 5) == 0:
                 self.progress_bar.print()
 
@@ -195,23 +204,22 @@
             for t_ in t:
                 p, alup = trajectory_module(initial_positions=tf.reshape(init_r, (-1, 3)), timing=t_, 
                                             **additional_kwargs, batch_index=tf.cast(idx, tf.int32))
                 pos.append(p)
                 add_lookups.append(alup)
             pos = tf.stack(pos, axis=1)
             pos = tf.reshape(pos, new_shape)
-            add_lookups = {k:tf.reshape(tf.stack([alup[k] for alup in add_lookups]),
-                                        tf.concat([new_shape[:-1], tf.shape(add_lookups[0][k])]))
+            add_lookups = {k: tf.reshape(tf.stack([alup[k] for alup in add_lookups]),
+                                         tf.concat([new_shape[:-1], tf.shape(add_lookups[0][k])]))
                            for k in add_lookups[0].keys()}
             
             batch.update({k: pos})
             batch.update(add_lookups)
         return batch
 
-
     def get_k_space_shape(self):
         """ Calculates the expected result shape of the simulated k-space, given the configuration
          of encoding and forward-model modules
 
         :return: tf.Tensor specifying the shape (#repetitions, #k_space_samples)
         """
         n_reps = tf.cast(self.forward_model.expected_number_of_repetitions, tf.int32)
@@ -282,12 +290,12 @@
         """
         # If set to True log the graph with tf.summary
         os.makedirs(graph_log_dir, exist_ok=True)
         writer = tf.summary.create_file_writer(graph_log_dir)
         print("Graph Tracing activated...")
         tf.summary.trace_on(graph=True)
         batch_dict, = [_ for _ in dataset(100).take(1)]
-        _ = self._segment_loop(batch_dict)
+        _ = self._segment_loop(**batch_dict)
 
         with writer.as_default():   # pylint: disable not-context-manager
             tf.summary.trace_export(name='graph_def', step=0)
         print(f'\nSaved Graph-definition to {graph_log_dir}')
```

## cmrsim/analytic/contrast/offresonance.py

```diff
@@ -41,15 +41,15 @@
                  expand_repetitions: bool, **kwargs):
         """
         :param sampling_times: timing of acquisition (ADC) events in milliseconds 
                                 of shape (#reps, #k-space-points) 
         :param gamma: Gyromagnetic ratio in rad/ms/mT
         """
 
-        super().__init__(expand_repetitions=expand_repetitions, name="static_t2star", **kwargs)
+        super().__init__(expand_repetitions=expand_repetitions, name="offres", **kwargs)
 
         if not(len(sampling_times.shape) == 1 or len(sampling_times.shape) == 2):
             raise ValueError("Invalid shape for specified sampling_times. "
                              "Must either be only (#k-space-points) or "
                              f"(#repetitions, #k-space-points), but is: {sampling_times.shape}")
         if len(sampling_times.shape) == 1:
             sampling_times = tf.reshape(sampling_times, [1, -1])
```

## cmrsim/analytic/encoding/_from_sequence.py

```diff
@@ -13,29 +13,35 @@
 
 # pylint: disable=abstract-method
 class GenericEncoding(BaseSampling):
     """" Interface to use cmr-seq definitions of k-space samples as encoder"""
     def __init__(self, name: str,
                  sequence: Union[cmrseq.Sequence, Iterable[cmrseq.Sequence]],
                  absolute_noise_std: Union[float, Iterable[float]],
+                 k_space_segments: int = None,
                  device: str = None):
         """
 
         :param name: Name of the module
         :param sequence: List or single instance of cmrseq.Sequence that implements the
                             calculate_kspace() function
         :param absolute_noise_std: Noise standard deviation
+        :param k_space_segments: If not specified, the number of sequences is used.
         :param device: Name of device that the operation is placed on
         """
 
         if isinstance(sequence, cmrseq.Sequence):
             sequence = [sequence, ]
+
+        if k_space_segments is None:
+            k_space_segments = len(sequence)
+
         self.sequence_list = sequence
         super().__init__(absolute_noise_std, name, device=device,
-                         k_space_segments=len(self.sequence_list))
+                         k_space_segments=tf.constant(k_space_segments, dtype=tf.int32))
 
     def _calculate_trajectory(self) -> (tf.Tensor, tf.Tensor):
         """ Calls the calculate_kspace() for all entries in self._sequence_list, stacks the k-space
         vectors and flattens the array()
         :return:  kspace-vectors, timing
         """
         k_space, timings = [], []
```

## cmrsim/analytic/encoding/base.py

```diff
@@ -13,15 +13,16 @@
 # pylint: disable=abstract-method
 class BaseSampling(tf.Module):
     """Base Module for implementing a time-dependent sampling in k-space. Is meant to be inherited
     from when specifying standard trajectories.
 
     :param absolute_noise_std: if < 0, add_noise() will leave signal unchanged
     :param name: (str) defining the module name-scope
-    :param k_space_segments: int
+    :param k_space_segments: Number of segments in k-space. Total number of samples divided by
+                                the number of segments must be an integer value
     :param device: str e.g. 'GPU:0'
      """
     # pylint: disable=too-many-instance-attributes
     #: Flat and unsegmented tensor of all sampling-event times.  Is set by a call of
     # abstract function self._calculate_trajectory. Expected shape: (-1, )
     sampling_times: tf.Variable
     #: Flat and unsegmented tensor of 3D k-space vectors corresponding to sampling-events.
@@ -86,14 +87,16 @@
         :return:
         """
         k_space_vectors, sampling_times = self._calculate_trajectory()
         self.k_space_vectors.assign(k_space_vectors)
         self.sampling_times.assign(sampling_times)
         self.number_of_samples = tf.size(self.sampling_times.read_value())
 
+        assert (self.number_of_samples % self.k_space_segments == 0)
+
         # Define segmented k-space trajectory for lower GPU memory requirements
         segment_size = tf.cast(tf.math.ceil(self.number_of_samples /
                                             self.k_space_segments.read_value()), tf.int32)
         total_element_count = self.k_space_segments.read_value() * segment_size
         difference = total_element_count - self.number_of_samples
         row_lengths = tf.constant([int(segment_size) for _ in
                                    tf.range(self.k_space_segments.read_value() - 1)] +
```

## cmrsim/analytic/encoding/cartesian.py

```diff
@@ -1,16 +1,16 @@
 """ This module contains all modules that are related to cartesian sampling strategies.
 """
 
 __all__ = ["EPI", "SingleLinePerShot"]
 
 from typing import List, Tuple, Union, Optional
+import warnings 
 
 import tensorflow as tf
-from deprecated import deprecated
 
 from cmrsim.analytic.encoding.base import BaseSampling
 
 
 # pylint: disable=abstract-method
 class SingleLinePerShot(BaseSampling):
     """ Encoding Module that assumes the handed in signal tensor in images space to be calculated
@@ -68,17 +68,15 @@
         dwell_time_centers = dwell_time_borders[:-1] + \
                              (dwell_time_borders[1:] - dwell_time_borders[:-1]) / 2
         sampling_times = tf.tile(dwell_time_centers,
                                  [self.matrix_size[1], ]) - self.readout_duration.read_value() / 2
         k_vectors = tf.einsum('ij, nj -> ni', tf.transpose(self.orientation), k_vectors)
         return k_vectors, sampling_times
 
-
-@deprecated(reason="Consider using the cmrsim.analytic.encoding.GenericEncoding class in"
-                   "combination with a cmrseq.sequence definition")
+        
 # pylint: disable=abstract-method
 class EPI(BaseSampling):
     """ Encoding Module implementing a single shot echo planar imaging trajectory.
      The subdivision into segments is solely used to manage memory limitation during simulation.
     """
     # pylint: disable=too-many-arguments
     def __init__(self, field_of_view: Union[Tuple[float, float], List[float]],
@@ -98,14 +96,16 @@
         :param read_out_duration: in ms, used to calculate sampling times (centers of
                                         dwell time intervals)
         :param bandwidth_per_pixel: in Hz, used to calculate read_out_duration
                                         (only one can be specified)
         :param blip_duration: in ms, time between readout events
         :param acquisition_start: in ms, leading offset prior to acquisition (defaults to 0.)
         """
+        warnings.warn("Consider using the cmrsim.analytic.encoding.GenericEncoding class in"
+                      "combination with a cmrseq.sequence definition", DeprecationWarning, stacklevel=2)
         if ((bandwidth_per_pixel is None and read_out_duration is None) or
                 (bandwidth_per_pixel is not None and read_out_duration is not None)):
             raise ValueError(f'Only exactly one of the arguments (pixel_bandwith/read_out_duration)'
                              f' must be specified. Instead pixel_bandwith: {bandwidth_per_pixel} '
                              f'and read_out_duration: {read_out_duration}, was given!')
 
         self.fov = tf.Variable(tf.constant(field_of_view), dtype=tf.float32, name='field_of_view')
```

## cmrsim/datasets/_cardiac_mesh.py

```diff
@@ -244,25 +244,26 @@
         in_slice = np.abs(distance) < slice_thickness.m_as("m") / 2
         mesh_copy = self.mesh.copy()
         current_slice = mesh_copy.remove_cells(np.where(np.logical_not(in_slice)),
                                                inplace=True)
         current_slice.reference_time = reference_time
         return current_slice
 
-    def get_trajectories(self, start: Quantity, end: Quantity) -> Tuple[Quantity, Quantity]:
+    def get_trajectories(self, start: Quantity, end: Quantity, string_cast: callable=float) -> Tuple[Quantity, Quantity]:
         """ Returns available times and positions between specified start-end
 
         :param start: Quantity
         :param end: Quantity
+        :param string_cast: callable to format the number to inserted as field name-time-stamp
         :return: time (t, ), positions (N, t, 3)
         """
         time_idx_start = np.searchsorted(self.timing, start.m_as("ms"), side="right")
         time_idx_end = np.searchsorted(self.timing, end.m_as("ms"), side="right")
         time = Quantity(self.timing[time_idx_start:time_idx_end], "ms")
-        positions = Quantity(np.stack([self.mesh.points + self.mesh[f"displacements_{t}ms"]
+        positions = Quantity(np.stack([self.mesh.points + self.mesh[f"displacements_{string_cast(t)}ms"]
                                        for t in time.m], axis=1), "m")
         return time, positions
 
 
 class CardiacMeshDataset(MeshDataset):
     """ Cardiac mesh model assuming the continuous node-ordering:
```

## cmrsim/trajectory/_base.py

```diff
@@ -64,12 +64,12 @@
         """ Returns a tiled tensor of the static positions
 
         :param initial_position: (N, 3)
         :param timing: (T, )
         :return: r_const - (T, N, 3)
         """
         n_steps = tf.shape(timing)[0]
-        return tf.tile(initial_positions[tf.newaxis], [n_steps, 1, 1]), {}
+        return tf.tile(initial_positions[:, tf.newaxis], [1, n_steps, 1]), {}
 
     def increment_particles(self, particle_positions: tf.Tensor, dt: tf.Tensor,
                             **kwargs) -> (tf.Tensor, dict):
         return particle_positions, {}
```

## cmrsim/trajectory/_proper_ortho_decomp.py

```diff
@@ -44,47 +44,61 @@
             ## reconstructed_states.shape == (#particles, 100, #channels)
 
 
     :param time_grid: (#time_steps)
     :param data: (#particles, #time_steps, #channels)
     :param n_modes: Number of modes used for reduce-order representation
     :param poly_order: Order of the Taylor-series used to fit the mode-weights
+    :param batch_size:
+    :param is_periodic:
     """
     #: Number of modes used for reduce-order representation
     n_modes: tf.Variable
     #: Computed basis-functions (modes) :math:`\phi_j` used to represent the input data in
     #: a reduced order. Shape (#particles * #channels, #modes)
     basis_function: tf.Variable
     #: Keeps track of the current timing when increment_particles is called.
     current_time_ms: tf.Variable
     #: Allows to only evaluate the position for a batch of stored particle trajectories
     current_batch_idx: tf.Variable
     #: Together with self.current_batch_size determines the subset of particle trajectories that
     #: is evaluated on call and increment_particles
     batch_size: tf.Variable
-
+    #:
+    ref_time: tf.Variable
+    #:
+    end_time: tf.Variable
+    #:
     _nchannels: tf.Variable
 
     def __init__(self, time_grid: np.ndarray, data: np.ndarray, n_modes: int,
-                 poly_order: int, batch_size: int = None):
+                 poly_order: int, batch_size: int = None,
+                 is_periodic: bool = False):
+
+        self.ref_time = tf.Variable(time_grid[0].astype(np.float32),
+                                    dtype=tf.float32, shape=(), trainable=False)
+        self.end_time = tf.Variable(time_grid[-1].astype(np.float32),
+                                    dtype=tf.float32, shape=(), trainable=False)
 
         self.n_modes = tf.Variable(n_modes, shape=(), dtype=tf.int32)
         self._nchannels = tf.Variable(data.shape[2], shape=(), dtype=tf.int32)
         phi, mode_weights = self.calculate_pod(time_grid, data, n_modes, remove_mean=False)
         self.basis_function = tf.Variable(phi, shape=(None, n_modes), dtype=tf.float32)
 
         if batch_size is not None:
             self.batch_size = tf.Variable(batch_size, dtype=tf.int32, shape=(), trainable=False)
         else:
             self.batch_size = tf.Variable(data.shape[0], dtype=tf.int32, shape=(), trainable=False)
         self.current_batch_idx = tf.Variable(0, dtype=tf.int32, shape=(), trainable=False)
         self._taylor_module = TaylorTrajectoryN(order=poly_order, time_grid=time_grid,
-                                    particle_trajectories=mode_weights.T.reshape(n_modes, -1, 1),
-                                    batch_size=None, fit_on_init=True)
+                                                particle_trajectories=mode_weights.T.reshape(n_modes, -1, 1),
+                                                batch_size=None, fit_on_init=True,
+                                                is_periodic=False)
 
+        self.is_periodic = tf.constant(is_periodic, dtype=tf.bool)
 
     @staticmethod
     def calculate_pod(time_grid: np.ndarray, data: np.ndarray, n_modes: int,
                       remove_mean: bool = False) -> (np.ndarray, np.ndarray):
         """Computes the proper orthogonal decomposition of data snapshots at points defined in
         `time_grid`. Returns only the `n_modes` number of most significant modes
 
@@ -119,15 +133,16 @@
 
         # (P*ch, t) @ (t, N) -> (P*ch, N)
         phi = np.dot(flat_sv, modes_cut)
 
         weights = np.einsum('pn, pt -> nt', flat_sv, phi)
         return phi, weights
 
-    def __call__(self, timing: tf.Tensor, batch_index: int = 0, **kwargs) -> (tf.Tensor, dict):
+    def __call__(self, initial_positions: tf.Tensor, timing: tf.Tensor,
+                 batch_index: int = 0, **kwargs) -> (tf.Tensor, dict):
         """Reconstructs the data state at given times t, by evaluating the taylor series
         of mode-weights and computing the weighted sum.
 
         :param timing: (#timesteps) in milliseconds
         :return: (#particles, #timesteps, self._channels), {}
         """
         idx_before = self.current_batch_idx.read_value()
@@ -156,18 +171,21 @@
     def _evaluate_trajectory(self, t: tf.Tensor) -> tf.Tensor:
         """Reconstructs the data state at given times t, by evaluating the taylor series
         of mode-weights and computing the weighted sum.
 
         :param t: (#steps) time-points to reconstruct at
         :return: data-states (#particles, #steps, #channels)
         """
+        t = t - self.ref_time
+        if self.is_periodic:
+            t = tf.math.floormod(t, self.end_time - self.ref_time)
+
         batch_start = self.current_batch_idx * self.batch_size * self._nchannels
         batch_end = batch_start + self.batch_size * self._nchannels
         # Evaluate mode weights from taylor-expansion -> shape: (t, N)
         mode_weights = tf.transpose(self._taylor_module._evaluate_trajectory(t)[:, :, 0], [1, 0])
         # Compute weighted sum of basis functions / modes to reconstruct data
         values_at_t = tf.einsum('pn, tn -> pt', self.basis_function[batch_start:batch_end],
                                 mode_weights)
-        print(values_at_t.shape)
         # Reshape according to input shapes (#particles, #steps, #channels)
         _shape = tf.stack([-1, self._nchannels, tf.shape(mode_weights)[0]], axis=0)
         return tf.transpose(tf.reshape(values_at_t, _shape), [0, 2, 1])
```

## cmrsim/trajectory/_taylor.py

```diff
@@ -43,14 +43,18 @@
     batch_size: tf.Variable
     #: Stores the order of the TaylorPolynomial, defined on instantiation
     order: tf.Variable
     #: Stores the result of fitting the TaylorPolynomial for all particle trajectories
     optimal_parameters: tf.Variable
     #: Is periodic
     is_periodic: tf.constant
+    #:
+    ref_time: tf.Variable
+    #:
+    end_time: tf.Variable
 
     # pylint: disable=too-many-arguments
     def __init__(self, order: int, time_grid: np.ndarray, particle_trajectories: np.ndarray,
                  batch_size: int = None, fit_on_init: bool = True, is_periodic: bool = False):
         """
         :param order: Order of the fitted TaylorPolynomial
         :param time_grid: (#timesteps, )
@@ -99,15 +103,15 @@
         coefficients = np.swapaxes(
             flat_coefficients.reshape(self._int_order + 1, n_particles, n_dims),
             0, 1)
         self.optimal_parameters.assign(coefficients.astype(np.float32))
 
     @tf.function
     def _evaluate_trajectory(self, t: tf.Tensor) -> tf.Tensor:
-        """ Evaluates the taylor expansion for a the current batch of particles at the specified
+        """ Evaluates the taylor expansion for the current batch of particles at the specified
         times t.
 
         :param t: (#timesteps)
         :return: (#particles, #timesteps, 3)
         """
         t = t - self.ref_time
         if self.is_periodic:
@@ -117,15 +121,16 @@
         factors = self.optimal_parameters[batch_start:batch_end]
         exponents = tf.range(0, tf.cast(self.order + 1, dtype=tf.float32))[:, tf.newaxis]
         t_pow_n = t[np.newaxis] ** exponents  # (order, time)
         out = tf.reduce_sum(factors[:, :, tf.newaxis] * t_pow_n[tf.newaxis, :, :, tf.newaxis],
                             axis=1)
         return out
 
-    def __call__(self, timing: tf.Tensor, batch_index: int = 0, **kwargs) -> (tf.Tensor, dict):
+    def __call__(self, initial_positions: tf.Tensor, timing: tf.Tensor,
+                 batch_index: int = 0, **kwargs) -> (tf.Tensor, dict):
         """ Evaluates the taylor expansion for the current batch of particles at the specified
         times t.
 
         :param timing: (#timesteps) in milliseconds
         :return: (#particles, #timesteps, 3) in meter
 
         """
```

## Comparing `cmrsim-0.26.dist-info/LICENSE` & `cmrsim-0.27.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `cmrsim-0.26.dist-info/METADATA` & `cmrsim-0.27.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: cmrsim
-Version: 0.26
+Version: 0.27
 Summary: UNKNOWN
 Home-page: https://gitlab.ethz.ch/jweine/cmrsim
 Author: Jonathan Weine, Charles McGrath
 License: UNKNOWN
 Project-URL: Documentation, https://people.ee.ethz.ch/~jweine/cmrsim/latest/index.html
 Project-URL: Source, https://gitlab.ethz.ch/jweine/cmrsim
 Project-URL: Institute, https://cmr.ethz.ch/
```

## Comparing `cmrsim-0.26.dist-info/RECORD` & `cmrsim-0.27.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,52 +1,52 @@
-cmrsim/__init__.py,sha256=sMa1VXpkgXzPdV3-Wqlcr7ij55H9A5exgxwNyAGzHiM,317
+cmrsim/__init__.py,sha256=ld1OQQnMal4IdQK_5f0BST4heeCLD7xvF2lNytM3wmA,317
 cmrsim/analytic/__init__.py,sha256=NuSQvtJg-2uNXpk2zNl8_jZnVFUcQUTmgGTtRNidY7U,354
-cmrsim/analytic/_composite_signal.py,sha256=QO9oGB4pE3p1wmYa6DWN9XpZZPkxgQ4q4FCf2nPGZdI,5002
-cmrsim/analytic/simulation.py,sha256=ZUh1QV3wQiHOSZVleBji1IZI2pOlLZqc1IuitPQ2qNc,14188
+cmrsim/analytic/_composite_signal.py,sha256=pnFTsDcYJm1IQCmOc5bgzlUT8KZJKzUUAFs7XTv0rkc,5193
+cmrsim/analytic/simulation.py,sha256=CaAi0BCZjTchlA-Wc3Cx8P8Dv1yrN9FRfIKFMvkrU18,14908
 cmrsim/analytic/contrast/__init__.py,sha256=SCgESekO5Hz6aGI9UPGHuLz1yAhE4GCMAeMze1Zqbko,790
 cmrsim/analytic/contrast/base.py,sha256=GIZqoOWCzrYekmXFbMBroJokF4Z4urwG0vfUk3S4EQo,15609
 cmrsim/analytic/contrast/coil_sensitivities.py,sha256=8wvS8V8iZ_k4jprj3mveC5tLelTn7U76h5FvQzKtF6E,12878
 cmrsim/analytic/contrast/diffusion_weighting.py,sha256=RGcQmAU-8WTTxPrUpLJK6jJmmAgs6wUYiuGEdMw3vOI,4067
-cmrsim/analytic/contrast/offresonance.py,sha256=Di4m75df20czXL0ib8u6M-RZ1q2YPjDh_dRTsMwlzwI,4797
+cmrsim/analytic/contrast/offresonance.py,sha256=5yxCkuxooTPUGL1uhwF-8Nx8-EnJhSzqYqa_rHJpIA0,4790
 cmrsim/analytic/contrast/phase_tracking.py,sha256=aPZrxDQHSsCHiXM9X5W2fULi4rsV1X18QMiVbp7aYg8,4409
 cmrsim/analytic/contrast/sequences.py,sha256=vqhmXlUjdJKkxjtkKGFmcLO2djZNS5mpRQXkahgIxTo,13174
 cmrsim/analytic/contrast/t2_star.py,sha256=1TIJVK7VCJliF_dY-iZZX_QbHTYrkCmVCOPA_XseIrI,4764
 cmrsim/analytic/encoding/__init__.py,sha256=JOmanhQ_Q8ld_dv_4WtJPXvz0HI_-F9O-dX6AXOZu4k,707
-cmrsim/analytic/encoding/_from_sequence.py,sha256=dFLFk1qSEs85hypj93MgbNco-4ekr-icH3liXIBg6n0,2010
-cmrsim/analytic/encoding/base.py,sha256=7F9i36t-ussBmRLj0CfcxwBqwTdV5PnHYHPqgToKanw,15979
-cmrsim/analytic/encoding/cartesian.py,sha256=lP1gHOpxuhepa4NZT5pj0NAlJ6QONkHRoFPqWTX_6uw,9365
+cmrsim/analytic/encoding/_from_sequence.py,sha256=iC57xKcBcda5pKeAqFQ-bINKrais5zNESgVthnd2WvM,2247
+cmrsim/analytic/encoding/base.py,sha256=cpZk-7p-aPd4GjA71WwHCdtUFwQqwQ3j9v-GUiuj0ho,16191
+cmrsim/analytic/encoding/cartesian.py,sha256=QsbtUu7P64jQi_HIAoU3CTN2hGizXx8NKoyfOggR7-8,9396
 cmrsim/bloch/__init__.py,sha256=yOOiwFJzQ_VyAXvwPtOo-Lt1ClItQ-MpcMW2BnMtWxU,493
 cmrsim/bloch/_base.py,sha256=mL556LQBeT04t_k7rbIyzn3mowTOvZewRB507bPSLg0,5423
 cmrsim/bloch/_generic.py,sha256=MAoUzcz4kP-WMGJvkP82zPZImjo4mkfgYOygkW649HE,27333
 cmrsim/bloch/_ideal.py,sha256=bdvxy7XDJ-FHfSEtJQElUyItoIi_1_xeSqeLS3TpT2I,3456
 cmrsim/bloch/_multi_coil.py,sha256=L4OtA0WN-49Sxfu9muJcf-QU8BE5QSpOYwgAw6CoGl8,6674
 cmrsim/bloch/submodules.py,sha256=Nz5cgrvwvL79ED5O2MvLzG5jbBbPQEZ5CZOFCZQ3aAc,7960
 cmrsim/datasets/__init__.py,sha256=6M0sq3lC51UXkZHqzz4bYr0nyqSsmpdkIq4LLioOWoY,702
 cmrsim/datasets/_analytic.py,sha256=rk7-H0N2DukfL0JmOQxQW5F_k2wJ1xAYvk1hVIVEYMQ,3804
 cmrsim/datasets/_base.py,sha256=u81LvuJZXaARTsBblVYzRfNUYWmCiibqCoMxIyNzZJI,2842
 cmrsim/datasets/_bloch.py,sha256=BKTFf17i_gtetC9t44Nu76TYizferzwX0Q9gLmHh7U8,1655
-cmrsim/datasets/_cardiac_mesh.py,sha256=BvnmCPS97RoznZrMwR1wurwa_VYLKMnNIxWHKoIvkEI,41423
+cmrsim/datasets/_cardiac_mesh.py,sha256=6tfw4wAAfiXThZBXVAzBou4jtO7eww5QmciCeQlE018,41560
 cmrsim/datasets/_flow.py,sha256=xRkMtOIDDHcEwRal-NBnpoca-SjCAOKjLVBbixOCR-E,23224
 cmrsim/datasets/_regular_grid.py,sha256=snowk30oL5Md6P4bA-OYRa2wbRvdZivyvGvLlFOmCk4,14057
 cmrsim/reconstruction/__init__.py,sha256=BtyMpXTuc44kylT7yDqcws9w1OWg5X-lvCyyDAFfY-E,140
 cmrsim/reconstruction/base.py,sha256=oLiZZpXVWlStNu81tF3kzkl9MyB09ctSSUvxRQhCOLo,1820
 cmrsim/reconstruction/cartesian.py,sha256=E-hBfhX5iKkK0RwWqu-wyuEYM5u3bCx0ka8rkle6sRA,6823
 cmrsim/simulation_templates/__init__.py,sha256=gVY--lD9ruZAiq0mEUR5Z-iarQQj4MLGO_NJM9AuPiQ,189
 cmrsim/simulation_templates/experimental_optimization.py,sha256=O93dDCQb6p5s0XNHkc3L2KE8QaB2ISlS7n3umIo8lVM,9173
 cmrsim/simulation_templates/flow.py,sha256=6-IbQoL6U2cU8i-KGHqAwHnmzton_spk8wMtpGoECiI,20333
 cmrsim/trajectory/__init__.py,sha256=zt2a2jGJz5QUNQtyO7524oJtBOdOxZ6Le2XQLuN38aU,1437
-cmrsim/trajectory/_base.py,sha256=JViZ-Iwo1epG1hLI84c_QiMtr0jJKI5pyRAKKBpRHx4,3296
+cmrsim/trajectory/_base.py,sha256=Z_Gk577q9EeX6lo2Ihq5VebuxGmo-_rjFx9QsJHhSkA,3299
 cmrsim/trajectory/_breathing.py,sha256=FDigWs7Jx2jZjQFvOJAofIvt0NIWbMAK19qMojQJuGI,5577
 cmrsim/trajectory/_diffusion.py,sha256=7FFpkl8Q2i5kmGM4B71tvCQQQdO3IPnnw0Xs7-k8gmk,8492
 cmrsim/trajectory/_flow.py,sha256=JG5KLzOGJ5RGVFhxzOkSrPo765Pj-VBqh5tCDo_8WQs,26071
-cmrsim/trajectory/_proper_ortho_decomp.py,sha256=Ld1S8N7945RcVWDHlguzUziSc0QiyCL3MggxmgRglRA,8394
-cmrsim/trajectory/_taylor.py,sha256=yhZp8aoZ7dL3dj1toAdo4jejSW4TOno4pVNThkR6GMU,7443
+cmrsim/trajectory/_proper_ortho_decomp.py,sha256=PeEdjdbVZkBQwsy9bNnLncUK5ee4b1Sbwu_2qDCjXiQ,9158
+cmrsim/trajectory/_taylor.py,sha256=0LmIm8p6TCzzKSmgRNThB4iYxfRVVO_4jyE8Y8v-XHI,7554
 cmrsim/utils/__init__.py,sha256=2RGU3ArstSrIT9aCTRhk_Bg0lfgKtx9fax4YosLcmLY,376
 cmrsim/utils/coordinates.py,sha256=v5K3HxuifZnhVa0gysJeP4hFdu49Z9Rhm5gbP6Q81G4,4170
 cmrsim/utils/display.py,sha256=RcxxU1etz0RdEcIO3YwRO-Ke4XzLGPjNMsSsesXm5As,6671
 cmrsim/utils/particle_properties.py,sha256=uQ39Bn-m8Pmqqh9ClmOI2OFt4Lc0K7GfKyCjzWSjvZg,1246
 cmrsim/utils/snr.py,sha256=0FzHqQF9ozoKxx1N9Gyzt93qL8cFGqjbkUTwXBlEapE,7023
-cmrsim-0.26.dist-info/LICENSE,sha256=YMlRaEyusWa3XSqFtOXCB46lJDU9CmwCp6s45xyijwY,35060
-cmrsim-0.26.dist-info/METADATA,sha256=2f64HKodaxzjgXfJab9OPHDSURLewVQDcOGbv2KlZJ0,3473
-cmrsim-0.26.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-cmrsim-0.26.dist-info/top_level.txt,sha256=nBnY6lAjSHggBmbuEyNTRh9ZWw0lnCrHZNgNxKGoRJQ,7
-cmrsim-0.26.dist-info/RECORD,,
+cmrsim-0.27.dist-info/LICENSE,sha256=YMlRaEyusWa3XSqFtOXCB46lJDU9CmwCp6s45xyijwY,35060
+cmrsim-0.27.dist-info/METADATA,sha256=-MvSlMC9A4W3VMci-Ad2cCMW6nKU6PDCxCzc0EXLcJE,3473
+cmrsim-0.27.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+cmrsim-0.27.dist-info/top_level.txt,sha256=nBnY6lAjSHggBmbuEyNTRh9ZWw0lnCrHZNgNxKGoRJQ,7
+cmrsim-0.27.dist-info/RECORD,,
```

